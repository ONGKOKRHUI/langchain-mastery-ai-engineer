{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96461273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.environ.get(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad6860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "#can use invoke method directly\n",
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0.5,\n",
    "    max_tokens=1000,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "response = model.invoke(\"Why do parrots talk?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce443993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"J'adore développer des applications.\" additional_kwargs={} response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'} id='lc_run--019b263a-bad1-7f51-bf99-6db1dbd058c8-0' usage_metadata={'input_tokens': 34, 'output_tokens': 532, 'total_tokens': 566, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 525}}\n"
     ]
    }
   ],
   "source": [
    "# can pass a conversation history in dic format\n",
    "\n",
    "conversation = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that translates English to French.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Translate: I love programming.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"J'adore la programmation.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Translate: I love building applications.\"}\n",
    "]\n",
    "\n",
    "response = model.invoke(conversation)\n",
    "print(response)  # AIMessage(\"J'adore créer des applications.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964a500b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"J'adore développer des applications.\" additional_kwargs={} response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'} id='lc_run--019b263b-901c-7581-9583-407bc5346485-0' usage_metadata={'input_tokens': 34, 'output_tokens': 221, 'total_tokens': 255, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 214}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import HumanMessage, AIMessage, SystemMessage\n",
    "#can pass a conversation history in message format\n",
    "\n",
    "conversation = [\n",
    "    SystemMessage(\"You are a helpful assistant that translates English to French.\"),\n",
    "    HumanMessage(\"Translate: I love programming.\"),\n",
    "    AIMessage(\"J'adore la programmation.\"),\n",
    "    HumanMessage(\"Translate: I love building applications.\")\n",
    "]\n",
    "\n",
    "\"\"\" \n",
    "human_msg = HumanMessage(\n",
    "    content=\"Hello!\",\n",
    "    name=\"alice\",  # Optional: identify different users\n",
    "    id=\"msg_123\",  # Optional: unique identifier for tracing\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "response = model.invoke(conversation)\n",
    "print(response)  # AIMessage(\"J'adore créer des applications.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaef6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parrots have incredibly colorful feathers due to a fascinating combination of evolutionary pressures and unique biological mechanisms. Here's a breakdown of the main reasons:\n",
      "\n",
      "1.  **Sexual Selection and Mate Attraction:**\n",
      "    *   **Signaling Health and Fitness|:** Bright, vibrant plumage is often an honest signal of a parrot's health, good diet, and strong genes. A parrot that can afford to produce and maintain such intense colors is likely good at foraging, avoids parasites, and is robust|. Potential mates are attracted to these displays as an indicator of a suitable partner.\n",
      "    *   **Display:** Many parrot species engage in elaborate courtship rituals where they show off their most brilliant feathers to attract a mate.\n",
      "\n",
      "2.  |**Species Recognition:**\n",
      "    *   In the dense, biodiverse environments where parrots live (like tropical rainforests), there can be many different bird species, sometimes even several parrot species. Distinct color patterns help parrots quickly recognize members of their own species|, preventing hybridization and ensuring they mate with the correct partner.\n",
      "\n",
      "3.  **Camouflage (Surprisingly!):**\n",
      "    *   While they might seem incredibly conspicuous in a plain room, a parrot's bright colors can actually provide| effective camouflage in their natural habitat. The dappled sunlight, vibrant flowers, colorful fruits, and lush green leaves of a tropical canopy create a visually \"noisy\" environment. A patchwork of reds, blues, greens, and yellows can help break| up a parrot's outline, allowing it to blend into the riot of colors and shadows, making it harder for predators (like hawks or monkeys) to spot them. This is often called **disruptive coloration**.\n",
      "\n",
      "4.  **Fl|ock Communication and Status:**\n",
      "    *   Within a flock, feather color can also play a role in social dynamics. Brighter, more dominant individuals might use their plumage to assert their status, and unique color patterns can help individuals recognize each other within a| large group.\n",
      "\n",
      "---\n",
      "\n",
      "### How Parrots Get Their Colors:\n",
      "\n",
      "The vibrant colors themselves are produced through two primary mechanisms:\n",
      "\n",
      "1.  **Pigments:**\n",
      "    *   **Carotenoids:** These are yellow, orange, and| red pigments that parrots obtain through their diet (e.g., from fruits, seeds, and vegetables). The availability of these pigments in their food directly influences the intensity of these colors.\n",
      "    *   **Psittacofulvins:** Unique| to parrots, these are a special class of pigments that parrots *synthesize themselves*. They are responsible for many of the brilliant red, orange, and yellow hues that are so characteristic of these birds.\n",
      "    *   **Melanins:** These| pigments produce blacks, browns, and grays, and can also contribute to the structural integrity of feathers.\n",
      "\n",
      "2.  **Structural Colors:**\n",
      "    *   **Blues and Greens:** Unlike reds and yellows, blues and many greens in| parrots are not caused by pigments. Instead, they are **structural colors**. This means that the microscopic structure of the feather barbules (tiny parts of the feather) scatter specific wavelengths of light while absorbing others.\n",
      "    *   When white| light hits these structures, the blue light is reflected, making the feather appear blue. Green is often achieved by a combination of structural blue and a yellow pigment (either carotenoid or psittacofulvin). This is why the color can| sometimes appear to shift slightly depending on the angle of the light.\n",
      "\n",
      "In summary, a parrot's colorful plumage is a multi-functional adaptation, driven by the need to attract mates, recognize their own kind, hide from predators, and| communicate within their complex tropical environments.||"
     ]
    }
   ],
   "source": [
    "#can stream model output\n",
    "\"\"\"\n",
    "Streaming only works if all steps in the program know how\n",
    " to process a stream of chunks. For instance, an \n",
    " application that isn’t streaming-capable would be one \n",
    " that needs to store the entire output in memory before \n",
    " it can be processed.\n",
    "\"\"\"\n",
    "for chunk in model.stream(\"Why do parrots have colorful feathers?\"):\n",
    "    print(chunk.text, end=\"|\", flush=True)\n",
    "\n",
    "\"\"\" \n",
    "During streaming, you’ll receive AIMessageChunk objects that can be combined into a full message object:\n",
    "chunks = []\n",
    "full_message = None\n",
    "for chunk in model.stream(\"Hi\"):\n",
    "    chunks.append(chunk)\n",
    "    print(chunk.text)\n",
    "    full_message = chunk if full_message is None else full_message + chunk\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b442ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Hello\n",
      "Token: Hello! How can I help you today?\n",
      "Token: \n",
      "Full message: Hello! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "#some advanced streaming with events\n",
    "async for event in model.astream_events(\"Hello\"):\n",
    "\n",
    "    if event[\"event\"] == \"on_chat_model_start\":\n",
    "        print(f\"Input: {event['data']['input']}\")\n",
    "\n",
    "    elif event[\"event\"] == \"on_chat_model_stream\":\n",
    "        print(f\"Token: {event['data']['chunk'].text}\")\n",
    "\n",
    "    elif event[\"event\"] == \"on_chat_model_end\":\n",
    "        print(f\"Full message: {event['data']['output'].text}\")\n",
    "\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41548c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Batch\n",
    "Batching a collection of independent requests to a model \n",
    "can significantly improve performance and reduce costs, \n",
    "as the processing can be done in parallel:\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "By default, batch() will only return the final output for the entire batch. \n",
    "If you want to receive the output for each individual input as it finishes g\n",
    "enerating, you can stream results with batch_as_completed():\n",
    "\"\"\"\n",
    "responses = model.batch([\n",
    "    \"Why do parrots have colorful feathers?\",\n",
    "    \"How do airplanes fly?\",\n",
    "    \"What is quantum computing?\"\n",
    "])\n",
    "for response in responses:\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f15ef34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool: get_weather\n",
      "Args: {'location': 'Boston'}\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "using Tools with the Model\n",
    "- allows the model to decide whether calling a tool is necessary \n",
    "- but it does not handle the tool execution itself \n",
    "- nor does the model receive the tool's output as part of its context\n",
    "- when bind, the model's response includes a request to execute a tool.\n",
    "\"\"\"\n",
    "\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Get the weather at a location.\"\"\"\n",
    "    return f\"It's sunny in {location}.\"\n",
    "\n",
    "\n",
    "model_with_tools = model.bind_tools([get_weather])  \n",
    "\n",
    "response = model_with_tools.invoke(\"What's the weather like in Boston?\")\n",
    "for tool_call in response.tool_calls:\n",
    "    # View tool calls made by the model\n",
    "    print(f\"Tool: {tool_call['name']}\")\n",
    "    print(f\"Args: {tool_call['args']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b29b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "If we want to execute the tools and pass the results\n",
    "we can loop the tool calls and invoke the tools\n",
    "then pass the results back to the model for final response\n",
    "\"\"\"\n",
    "# Bind (potentially multiple) tools to the model\n",
    "model_with_tools = model.bind_tools([get_weather])\n",
    "\n",
    "# Step 1: Model generates tool calls\n",
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather in Boston?\"}]\n",
    "ai_msg = model_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)\n",
    "\n",
    "# Step 2: Execute tools and collect results\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    # Execute the tool with the generated arguments\n",
    "    tool_result = get_weather.invoke(tool_call)\n",
    "    messages.append(tool_result)\n",
    "\n",
    "# Step 3: Pass results back to model for final response\n",
    "final_response = model_with_tools.invoke(messages)\n",
    "print(final_response.text)\n",
    "# \"The current weather in Boston is 72°F and sunny.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ef1e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can specify which tool to use if multiple are bound\n",
    "# this is by default \"any\" \n",
    "model_with_tools = model.bind_tools([tool_1], tool_choice=\"tool_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed087b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool: get_weather\n",
      "ID: 70ba4b9c-38dd-429a-b962-a90f420b270b\n",
      "Args: {\"location\": \"Boston\"}\n",
      "Tool: get_weather\n",
      "ID: 87820713-6eef-4880-a379-d341e5d9c61e\n",
      "Args: {\"location\": \"Tokyo\"}\n"
     ]
    }
   ],
   "source": [
    "# just to stream tool call chunks instead of full tool call\n",
    "for chunk in model_with_tools.stream(\n",
    "    \"What's the weather in Boston and Tokyo?\"\n",
    "):\n",
    "    # Tool call chunks arrive progressively\n",
    "    for tool_chunk in chunk.tool_call_chunks:\n",
    "        if name := tool_chunk.get(\"name\"):\n",
    "            print(f\"Tool: {name}\")\n",
    "        if id_ := tool_chunk.get(\"id\"):\n",
    "            print(f\"ID: {id_}\")\n",
    "        if args := tool_chunk.get(\"args\"):\n",
    "            print(f\"Args: {args}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed250113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'get_weather', 'args': {'location': 'Boston'}, 'id': 'fb88294c-ebf7-46ed-abe4-98d4c7173d59', 'type': 'tool_call'}]\n",
      "[{'name': 'get_weather', 'args': {'location': 'Boston'}, 'id': 'fb88294c-ebf7-46ed-abe4-98d4c7173d59', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "gathered = None\n",
    "for chunk in model_with_tools.stream(\"What's the weather in Boston?\"):\n",
    "    gathered = chunk if gathered is None else gathered + chunk\n",
    "    print(gathered.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d67f4c",
   "metadata": {},
   "source": [
    "### Structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "674bb775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title='Inception' year=2010 director='Christopher Nolan' rating=8.8\n"
     ]
    }
   ],
   "source": [
    "# pydantic\n",
    "# provide the richest feature set with \n",
    "# field validation, descriptions, and nested structures.\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Movie(BaseModel):\n",
    "    \"\"\"A movie with details.\"\"\"\n",
    "    title: str = Field(..., description=\"The title of the movie\")\n",
    "    year: int = Field(..., description=\"The year the movie was released\")\n",
    "    director: str = Field(..., description=\"The director of the movie\")\n",
    "    rating: float = Field(..., description=\"The movie's rating out of 10\")\n",
    "\n",
    "model_with_structure = model.with_structured_output(Movie)\n",
    "response = model_with_structure.invoke(\"Provide details about the movie Inception\")\n",
    "print(response)  # Movie(title=\"Inception\", year=2010, director=\"Christopher Nolan\", rating=8.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030f7912",
   "metadata": {},
   "outputs": [],
   "source": [
    "#provides a simpler alternative using Python’s built-in typing, \n",
    "# ideal when you don’t need runtime validation.\n",
    "\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "\n",
    "class MovieDict(TypedDict):\n",
    "    \"\"\"A movie with details.\"\"\"\n",
    "    title: Annotated[str, ..., \"The title of the movie\"]\n",
    "    year: Annotated[int, ..., \"The year the movie was released\"]\n",
    "    director: Annotated[str, ..., \"The director of the movie\"]\n",
    "    rating: Annotated[float, ..., \"The movie's rating out of 10\"]\n",
    "\n",
    "model_with_structure = model.with_structured_output(MovieDict)\n",
    "response = model_with_structure.invoke(\"Provide details about the movie Inception\")\n",
    "print(response)  # {'title': 'Inception', 'year': 2010, 'director': 'Christopher Nolan', 'rating': 8.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93b65b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For maximum control or interoperability, \n",
    "# you can provide a raw JSON Schema.\n",
    "import json\n",
    "\n",
    "json_schema = {\n",
    "    \"title\": \"Movie\",\n",
    "    \"description\": \"A movie with details\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"title\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The title of the movie\"\n",
    "        },\n",
    "        \"year\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"description\": \"The year the movie was released\"\n",
    "        },\n",
    "        \"director\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The director of the movie\"\n",
    "        },\n",
    "        \"rating\": {\n",
    "            \"type\": \"number\",\n",
    "            \"description\": \"The movie's rating out of 10\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"title\", \"year\", \"director\", \"rating\"]\n",
    "}\n",
    "\n",
    "model_with_structure = model.with_structured_output(\n",
    "    json_schema,\n",
    "    method=\"json_schema\",\n",
    ")\n",
    "response = model_with_structure.invoke(\"Provide details about the movie Inception\")\n",
    "print(response)  # {'title': 'Inception', 'year': 2010, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8068b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nested structures with Pydantic\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Actor(BaseModel):\n",
    "    name: str\n",
    "    role: str\n",
    "\n",
    "class MovieDetails(BaseModel):\n",
    "    title: str\n",
    "    year: int\n",
    "    cast: list[Actor]\n",
    "    genres: list[str]\n",
    "    budget: float | None = Field(None, description=\"Budget in millions USD\")\n",
    "\n",
    "model_with_structure = model.with_structured_output(MovieDetails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986bd58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can access metadata like toke counts using include_raw = True\n",
    "# for parsed structure\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Movie(BaseModel):\n",
    "    \"\"\"A movie with details.\"\"\"\n",
    "    title: str = Field(..., description=\"The title of the movie\")\n",
    "    year: int = Field(..., description=\"The year the movie was released\")\n",
    "    director: str = Field(..., description=\"The director of the movie\")\n",
    "    rating: float = Field(..., description=\"The movie's rating out of 10\")\n",
    "\n",
    "model_with_structure = model.with_structured_output(Movie, include_raw=True)  \n",
    "response = model_with_structure.invoke(\"Provide details about the movie Inception\")\n",
    "response\n",
    "# {\n",
    "#     \"raw\": AIMessage(...),\n",
    "#     \"parsed\": Movie(title=..., year=..., ...),\n",
    "#     \"parsing_error\": None,\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371f1ee8",
   "metadata": {},
   "source": [
    "### Multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd99428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.invoke(\"Create a picture of a cat\")\n",
    "print(response.content_blocks)\n",
    "# [\n",
    "#     {\"type\": \"text\", \"text\": \"Here's a picture of a cat\"},\n",
    "#     {\"type\": \"image\", \"base64\": \"...\", \"mime_type\": \"image/jpeg\"},\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c1be51",
   "metadata": {},
   "source": [
    "### Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af33bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in model.stream(\"Why do parrots have colorful feathers?\"):\n",
    "    reasoning_steps = [r for r in chunk.content_blocks if r[\"type\"] == \"reasoning\"]\n",
    "    print(reasoning_steps if reasoning_steps else chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "653a820e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(\"Why do parrots have colorful feathers?\")\n",
    "reasoning_steps = [b for b in response.content_blocks if b[\"type\"] == \"reasoning\"]\n",
    "print(\" \".join(step[\"reasoning\"] for step in reasoning_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34df8e14",
   "metadata": {},
   "source": [
    "### Server side tool use\n",
    "- use the provided tool from the LLM provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b70483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "tool = {\"type\": \"web_search\"}\n",
    "model_with_tools = model.bind_tools([tool])\n",
    "\n",
    "response = model_with_tools.invoke(\"What was a positive news story from today?\")\n",
    "response.content_blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32d1595",
   "metadata": {},
   "source": [
    "### Rate limiter\n",
    "- limit the number of requests to the LLM provider\n",
    "- avoid overloading the LLM provider and rate limit error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742f07e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
    "\n",
    "rate_limiter = InMemoryRateLimiter(\n",
    "    requests_per_second=0.1,  # 1 request every 10s\n",
    "    check_every_n_seconds=0.1,  # Check every 100ms whether allowed to make a request\n",
    "    max_bucket_size=10,  # Controls the maximum burst size.\n",
    ")\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=\"gpt-5\",\n",
    "    model_provider=\"openai\",\n",
    "    rate_limiter=rate_limiter  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b78e04",
   "metadata": {},
   "source": [
    "### Tracking Token Usage\n",
    "- using callback OR\n",
    "- using context manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4a7b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use callback handler as part of config\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.callbacks import UsageMetadataCallbackHandler\n",
    "\n",
    "model_1 = init_chat_model(model=\"gpt-4o-mini\")\n",
    "model_2 = init_chat_model(model=\"claude-haiku-4-5-20251001\")\n",
    "\n",
    "callback = UsageMetadataCallbackHandler()\n",
    "result_1 = model_1.invoke(\"Hello\", config={\"callbacks\": [callback]})\n",
    "result_2 = model_2.invoke(\"Hello\", config={\"callbacks\": [callback]})\n",
    "callback.usage_metadata\n",
    "\n",
    "OUTPUT:\n",
    "{\n",
    "    'gpt-4o-mini-2024-07-18': {\n",
    "        'input_tokens': 8,\n",
    "        'output_tokens': 10,\n",
    "        'total_tokens': 18,\n",
    "        'input_token_details': {'audio': 0, 'cache_read': 0},\n",
    "        'output_token_details': {'audio': 0, 'reasoning': 0}\n",
    "    },\n",
    "    'claude-haiku-4-5-20251001': {\n",
    "        'input_tokens': 8,\n",
    "        'output_tokens': 21,\n",
    "        'total_tokens': 29,\n",
    "        'input_token_details': {'cache_read': 0, 'cache_creation': 0}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3420c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE context manager using with statement\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.callbacks import get_usage_metadata_callback\n",
    "\n",
    "model_1 = init_chat_model(model=\"gpt-4o-mini\")\n",
    "model_2 = init_chat_model(model=\"claude-haiku-4-5-20251001\")\n",
    "\n",
    "with get_usage_metadata_callback() as cb:\n",
    "    model_1.invoke(\"Hello\")\n",
    "    model_2.invoke(\"Hello\")\n",
    "    print(cb.usage_metadata)\n",
    "\n",
    "OUTPUT:\n",
    "{\n",
    "    'gpt-4o-mini-2024-07-18': {\n",
    "        'input_tokens': 8,\n",
    "        'output_tokens': 10,\n",
    "        'total_tokens': 18,\n",
    "        'input_token_details': {'audio': 0, 'cache_read': 0},\n",
    "        'output_token_details': {'audio': 0, 'reasoning': 0}\n",
    "    },\n",
    "    'claude-haiku-4-5-20251001': {\n",
    "        'input_tokens': 8,\n",
    "        'output_tokens': 21,\n",
    "        'total_tokens': 29,\n",
    "        'input_token_details': {'cache_read': 0, 'cache_creation': 0}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829c7b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Invocation config\n",
    "When invoking a model, you can pass additional configuration through the config parameter using a RunnableConfig dictionary. This provides run-time control over execution behavior, callbacks, and metadata tracking.\n",
    "\n",
    "These configuration values are particularly useful when:\n",
    "Debugging with LangSmith tracing\n",
    "Implementing custom logging or monitoring\n",
    "Controlling resource usage in production\n",
    "Tracking invocations across complex pipelines\n",
    "\"\"\"\n",
    "response = model.invoke(\n",
    "    \"Tell me a joke\",\n",
    "    config={\n",
    "        \"run_name\": \"joke_generation\",      # Custom name for this run\n",
    "        \"tags\": [\"humor\", \"demo\"],          # Tags for categorization\n",
    "        \"metadata\": {\"user_id\": \"123\"},     # Custom metadata\n",
    "        \"callbacks\": [my_callback_handler], # Callback handlers\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571ce8f1",
   "metadata": {},
   "source": [
    "### Configurable model on runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45debed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "configurable_model = init_chat_model(temperature=0)\n",
    "\n",
    "configurable_model.invoke(\n",
    "    \"what's your name\",\n",
    "    config={\"configurable\": {\"model\": \"gpt-5-nano\"}},  # Run with GPT-5-Nano\n",
    ")\n",
    "configurable_model.invoke(\n",
    "    \"what's your name\",\n",
    "    config={\"configurable\": {\"model\": \"claude-sonnet-4-5-20250929\"}},  # Run with Claude\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee41216",
   "metadata": {},
   "source": [
    "### Tool Call ToolMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f744137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import AIMessage\n",
    "from langchain.messages import ToolMessage\n",
    "\n",
    "# After a model makes a tool call\n",
    "# (Here, we demonstrate manually creating the messages for brevity)\n",
    "ai_message = AIMessage(\n",
    "    content=[],\n",
    "    tool_calls=[{\n",
    "        \"name\": \"get_weather\",\n",
    "        \"args\": {\"location\": \"San Francisco\"},\n",
    "        \"id\": \"call_123\"\n",
    "    }]\n",
    ")\n",
    "\n",
    "# Execute tool and create result message\n",
    "weather_result = \"Sunny, 72°F\"\n",
    "tool_message = ToolMessage(\n",
    "    content=weather_result,\n",
    "    tool_call_id=\"call_123\"  # Must match the call ID\n",
    ")\n",
    "\n",
    "# Continue conversation\n",
    "messages = [\n",
    "    HumanMessage(\"What's the weather in San Francisco?\"),\n",
    "    ai_message,  # Model's tool call\n",
    "    tool_message,  # Tool execution result\n",
    "]\n",
    "response = model.invoke(messages)  # Model processes the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b3e1ec",
   "metadata": {},
   "source": [
    "### Message Content\n",
    "- You can think of a message’s content as the payload of data that gets sent to the model.\n",
    "Messages have a content attribute that is loosely-typed, supporting strings and lists of untyped objects (e.g., dictionaries). This allows support for provider-native structures directly in LangChain chat models, such as multimodal content and other data.\n",
    "LangChain chat models accept message content in the content attribute.\n",
    "This may contain either:\n",
    "A string\n",
    "A list of content blocks in a provider-native format\n",
    "A list of LangChain’s standard content blocks\n",
    "See below for an example using multimodal inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec0031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "# String content\n",
    "human_message = HumanMessage(\"Hello, how are you?\")\n",
    "\n",
    "# Provider-native format (e.g., OpenAI)\n",
    "human_message = HumanMessage(content=[\n",
    "    {\"type\": \"text\", \"text\": \"Hello, how are you?\"},\n",
    "    {\"type\": \"image_url\", \"image_url\": {\"url\": \"https://example.com/image.jpg\"}}\n",
    "])\n",
    "\n",
    "# List of standard content blocks\n",
    "human_message = HumanMessage(content_blocks=[\n",
    "    {\"type\": \"text\", \"text\": \"Hello, how are you?\"},\n",
    "    {\"type\": \"image\", \"url\": \"https://example.com/image.jpg\"},\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f716af4c",
   "metadata": {},
   "source": [
    "Standard content blocks\n",
    "LangChain provides a standard representation for message content that works across providers.\n",
    "Message objects implement a content_blocks property that will lazily parse the content attribute into a standard, type-safe representation. For example, messages generated from ChatAnthropic or ChatOpenAI will include thinking or reasoning blocks in the format of the respective provider, but can be lazily parsed into a consistent ReasoningContentBlock representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c52b426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import AIMessage\n",
    "\n",
    "message = AIMessage(\n",
    "    content=[\n",
    "        {\n",
    "            \"type\": \"reasoning\",\n",
    "            \"id\": \"rs_abc123\",\n",
    "            \"summary\": [\n",
    "                {\"type\": \"summary_text\", \"text\": \"summary 1\"},\n",
    "                {\"type\": \"summary_text\", \"text\": \"summary 2\"},\n",
    "            ],\n",
    "        },\n",
    "        {\"type\": \"text\", \"text\": \"...\", \"id\": \"msg_abc123\"},\n",
    "    ],\n",
    "    response_metadata={\"model_provider\": \"openai\"}\n",
    ")\n",
    "message.content_blocks\n",
    "OUTPUT:\n",
    "[{'type': 'reasoning', 'id': 'rs_abc123', 'reasoning': 'summary 1'},\n",
    " {'type': 'reasoning', 'id': 'rs_abc123', 'reasoning': 'summary 2'},\n",
    " {'type': 'text', 'text': '...', 'id': 'msg_abc123'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c104cf28",
   "metadata": {},
   "source": [
    "## Multimodality\n",
    "- work with data input in different forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfa6117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image\n",
    "\n",
    "# From URL\n",
    "message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"Describe the content of this image.\"},\n",
    "        {\"type\": \"image\", \"url\": \"https://example.com/path/to/image.jpg\"},\n",
    "    ]\n",
    "}\n",
    "\n",
    "# From base64 data\n",
    "message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"Describe the content of this image.\"},\n",
    "        {\n",
    "            \"type\": \"image\",\n",
    "            \"base64\": \"AAAAIGZ0eXBtcDQyAAAAAGlzb21tcDQyAAACAGlzb2...\",\n",
    "            \"mime_type\": \"image/jpeg\",\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "# From provider-managed File ID\n",
    "message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"Describe the content of this image.\"},\n",
    "        {\"type\": \"image\", \"file_id\": \"file-abc123\"},\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120ca558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdf\n",
    "\n",
    "# From URL\n",
    "message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"Describe the content of this document.\"},\n",
    "        {\"type\": \"file\", \"url\": \"https://example.com/path/to/document.pdf\"},\n",
    "    ]\n",
    "}\n",
    "\n",
    "# From base64 data\n",
    "message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"Describe the content of this document.\"},\n",
    "        {\n",
    "            \"type\": \"file\",\n",
    "            \"base64\": \"AAAAIGZ0eXBtcDQyAAAAAGlzb21tcDQyAAACAGlzb2...\",\n",
    "            \"mime_type\": \"application/pdf\",\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "# From provider-managed File ID\n",
    "message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"Describe the content of this document.\"},\n",
    "        {\"type\": \"file\", \"file_id\": \"file-abc123\"},\n",
    "    ]\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
